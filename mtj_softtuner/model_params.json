{
  "GPT-Neo-2.7B": {
    "tokenizer_id": "gpt2",
    "newlinemode": "n",
    "params": {
      "compat": "neo",
      "layers": 32,
      "d_model": 2560,
      "n_heads": 20,
      "n_vocab": 50257,
      "n_vocab_padding": 143,
      "norm": "layernorm",
      "pe": "fixed",
      "seq": 2048,
      "cores_per_replica": 4,
      "eos_token": [50256],
      "max_batch_size": 2048
    }
  },
  "GPT-Neo-1.3B": {
    "tokenizer_id": "gpt2",
    "newlinemode": "n",
    "params": {
      "compat": "neo",
      "layers": 24,
      "d_model": 2048,
      "n_heads": 16,
      "n_vocab": 50257,
      "n_vocab_padding": 143,
      "norm": "layernorm",
      "pe": "fixed",
      "seq": 2048,
      "cores_per_replica": 8,
      "eos_token": [50256],
      "max_batch_size": 2048
    }
  },
  "fairseq-dense-125M": {
    "tokenizer_id": "KoboldAI/fairseq-dense-125M",
    "newlinemode": "s",
    "params": {
      "compat": "fairseq_lm",
      "n_vocab": 50261,
      "n_vocab_padding": 943,
      "norm": "layernorm",
      "pe": "fairseq_sinusoidal",
      "seq": 2048,
      "layers": 12,
      "d_model": 768,
      "n_heads": 12,
      "cores_per_replica": 6,
      "eos_token": [50259, 50259],
      "max_batch_size": 2048
    }
  },
  "fairseq-dense-355M": {
    "tokenizer_id": "KoboldAI/fairseq-dense-125M",
    "newlinemode": "s",
    "params": {
      "compat": "fairseq_lm",
      "n_vocab": 50261,
      "n_vocab_padding": 939,
      "norm": "layernorm",
      "pe": "fairseq_sinusoidal",
      "seq": 2048,
      "layers": 24,
      "d_model": 1024,
      "n_heads": 16,
      "cores_per_replica": 8,
      "eos_token": [50259, 50259],
      "max_batch_size": 2048
    }
  },
  "fairseq-dense-760M": {
    "tokenizer_id": "KoboldAI/fairseq-dense-125M",
    "newlinemode": "s",
    "params": {
      "compat": "fairseq_lm",
      "n_vocab": 50261,
      "n_vocab_padding": 939,
      "norm": "layernorm",
      "pe": "fairseq_sinusoidal",
      "seq": 2048,
      "layers": 24,
      "d_model": 1536,
      "n_heads": 16,
      "cores_per_replica": 8,
      "eos_token": [50259, 50259],
      "max_batch_size": 2048
    }
  },
  "fairseq-dense-1.3B": {
    "tokenizer_id": "KoboldAI/fairseq-dense-125M",
    "newlinemode": "s",
    "params": {
      "compat": "fairseq_lm",
      "n_vocab": 50261,
      "n_vocab_padding": 939,
      "norm": "layernorm",
      "pe": "fairseq_sinusoidal",
      "seq": 2048,
      "layers": 24,
      "d_model": 2048,
      "n_heads": 32,
      "cores_per_replica": 8,
      "eos_token": [50259, 50259],
      "max_batch_size": 2048
    }
  },
  "fairseq-dense-2.7B": {
    "tokenizer_id": "KoboldAI/fairseq-dense-125M",
    "newlinemode": "s",
    "params": {
      "compat": "fairseq_lm",
      "n_vocab": 50261,
      "n_vocab_padding": 939,
      "norm": "layernorm",
      "pe": "fairseq_sinusoidal",
      "seq": 2048,
      "layers": 32,
      "d_model": 2560,
      "n_heads": 32,
      "cores_per_replica": 8,
      "eos_token": [50259, 50259],
      "max_batch_size": 2048
    }
  },
  "fairseq-dense-6.7B": {
    "tokenizer_id": "KoboldAI/fairseq-dense-125M",
    "newlinemode": "s",
    "params": {
      "compat": "fairseq_lm",
      "n_vocab": 50261,
      "n_vocab_padding": 939,
      "norm": "layernorm",
      "pe": "fairseq_sinusoidal",
      "seq": 2048,
      "layers": 32,
      "d_model": 4096,
      "n_heads": 32,
      "cores_per_replica": 8,
      "eos_token": [50259, 50259],
      "max_batch_size": 2048
    }
  },
  "fairseq-dense-13B": {
    "tokenizer_id": "KoboldAI/fairseq-dense-125M",
    "newlinemode": "s",
    "params": {
      "compat": "fairseq_lm",
      "n_vocab": 50261,
      "n_vocab_padding": 939,
      "norm": "layernorm",
      "pe": "fairseq_sinusoidal",
      "seq": 2048,
      "layers": 40,
      "d_model": 5120,
      "n_heads": 40,
      "cores_per_replica": 8,
      "eos_token": [50259, 50259],
      "max_batch_size": 450
    }
  },
  "GPT-J-6B": {
    "tokenizer_id": "gpt2",
    "newlinemode": "n",
    "params": {
      "layers": 28,
      "d_model": 4096,
      "n_heads": 16,
      "n_vocab": 50257,
      "n_vocab_padding": 143,
      "norm": "layernorm",
      "pe": "rotary",
      "pe_rotary_dims": 64,
      "seq": 2048,
      "cores_per_replica": 8,
      "eos_token": [50256],
      "max_batch_size": 2048
    }
  }
}
